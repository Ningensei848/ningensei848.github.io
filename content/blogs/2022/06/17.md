---
# @see https://docusaurus.io/docs/api/plugins/@docusaurus/plugin-content-blog#markdown-front-matter
# Metadata (Recommended) ------------------------------------
title: "Tweet を不特定多数の人々\"を利用して\"集めたい"
date: "2022-06-17"
tags:
  - "Twitter"
  - "hcomp"
# draft: true  # if true, the article is `WIP` and therefore should not be published yet
# Allows to customize the blog post url (/<routeBasePath>/<slug>)
# slug: ''   # default is current file path
authors: kiai  # @see authors.yml
# -----------------------------------------------------------
# Additional ------------------------------------------------
# hide_table_of_contents:   # if true, rightside ToC will be invisible
# toc_min_heading_level: 2  # The minimum heading level shown in the ToC
# toc_max_heading_level: 3  # The max heading level shown in the ToC
# for SEO
keywords:
  - "Twitter"
  - "hcomp"
# description: '<Desc>'
# for `og:image` and `twitter:image` (.png or .jpg, NOT .svg)
image: https://custom-og-image-generator.vercel.app/api/Tweet%20%E3%82%92%E4%B8%8D%E7%89%B9%E5%AE%9A%E5%A4%9A%E6%95%B0%E3%81%AE%E4%BA%BA%E3%80%85%22%E3%82%92%E5%88%A9%E7%94%A8%E3%81%97%E3%81%A6%22%E9%9B%86%E3%82%81%E3%81%9F%E3%81%84.png?theme=light&copyright=Kiai+de+Nantoka&logo=https%3A%2F%2Fabs.twimg.com%2Fresponsive-web%2Fclient-web%2Ficon-svg.168b89d8.svg&avater=https%3A%2F%2Favatars.githubusercontent.com%2Fu%2F20794309&author=Kiai&aka=%40Ningensei848&site=%E6%B0%97%E5%90%88%E3%81%A7%E3%81%AA%E3%82%93%E3%81%A8%E3%81%8B&tags=Twitter&tags=hcomp
---

「～を利用して」という表現には「個々人に "集めさせる"」という意図がある。
すなわち、Twitter API を個人で利用する分にはたかだか５０万 tw/month 程度までしか収集できない一方で、複数人の力を合わせればその量を N 倍に増やせるという企みである。

じゃあ、どうやってそれを実現するのか？ということを考えているので、それをメモしておく。

<!-- truncate -->

## 手順

1. ツイート収集メソッドの確立
2. 収集動機の言語化
3. データを分析できるツールの開発

## ツイート収集メソッド

**素人でもツイートを集められる方法を確立する**

まず自分のツイートを利用して「ツイート収集ツール」の公開リポジトリを用意する。
これは、対象の user_id を列挙しておけば定期的にスクリプトが走ってツイートを保存するというものだ。

あとは GitHub アカウントの作成からリポジトリのクローン、user_id の編集、リポジトリの private 化、 Actions の有効化……等々のインストラクションを記事にして共有すれば、誰でもツイートを集めうる。

:::caution

**リポジトリの private 化** は必須である。
なぜなら著作権的に怒られる可能性が高いからだ。

例として挙げる自分のリポジトリについては、著作権の放棄を明記するか、対象のデータを明示的に削除できるスクリプトもオプションでつけておくべきだろう。
:::

また、エディタを持たない一般の素人には、ファイル編集でさえも億劫となるかもしれない問題がある。
こちらは、GitHub がブラウザ上で提供するエディタでファイル一つだけを編集できるようにすればよいと思われる。
初見では戸惑うであろう `git add` `git commit` 等の操作を省略できるのも好材料だろう。

こういった一つ一つのアプローチについて、[zenn](https://zenn.dev/ningensei848) なり [note](https://note.com/ningensei848) なりに手順を事細かに述べておくとよい。

## 動機の言語化

**集めたいと思わせる動機を言語化して認知させる**

ツイートを集められる状況が整ったとして、それをどう使うのかという点が明らかではないと行動へ移しづらいだろう。
プログラミングやデータ分析など考えたこともない一般人であればなおさらである。

例えば、訴訟での証拠としてツイートが採用されることがあるが、単なるスクショよりも信頼性の高いデータを得ることができる。
本文はもとより、ツイートされた日時、それを取得した日時、その時点での RT 数等も取得できる。

[Web 魚拓](https://megalodon.jp)等の外部サービスとは異なり、自分だけが届く範囲にデータを置くことで意図せず削除される心配がない。
ツイ消しの憂き目に会っても、自分だけは生データを持っているというアドバンテージを得られる。

また、API の制限こそあれど、その範囲内であれば複数のアカウントに対してツイートを取得することができる（一人に対して１リポジトリといった運用を避けられる）。
加えて、「いいねしたツイート」も並行して集めることができる。

さらに、次の述べるような分析ツールに丸々データを投げ込むことで、データを可視化することができるかもしれない。

## 分析ツールの開発

**集めたツイートを分析できるツールを設置する**

検索はもとより、ワードクラウドで頻出単語群を見やすくしたり、リプライを交わす仲の良いアカウントが誰なのか人目でわかるようにしたり、いいねしがちなツイートの傾向を探ったりできる。
本来であれば自分のアカウントで連携サービスに許可を出した上で自分のアカウントに対してしか実行できなかった操作を、他人についてもできるとなればかなり魅力的ではないだろうか。

……といったところで、規約的な問題が発生しそうなことにも気がついた。

### 懸念：シェアしたい

「結果をシェアしたい！」という要望が多く生まれると想定されるが、1⃣ 他人のデータを勝手に抜いて 2⃣ 分析ツールに突っ込み 3⃣ 結果を広く公衆に掲示する　という場合、どこかでなにかしら引っかかりそうだ。

現状の感覚として、1⃣2⃣ は問題なく行えそうだが、3⃣ については Twitter 側の規約に違反していそうな気がする。

一方で、あくまで二次的なデータだけであれば、そこについてツイート主体が権利侵害を訴えることはできない（なんの権利も侵害していないため）。

既存のツイートデータ分析ツールは「自分のツイート」に対して、連携サービスに許可を出した上で分析させるものであって、ツイートした主体が異なる場合はどうなるのか不明である。
この「許可を出す」のは、API 経由でツイートを取得するためだけということであれば、権利主体が異なっても特段問題はないのだろうか…

## まとめ

３つの手順をこなして、実際に分析ツールを使ってくれるようになれば、**そのバックエンドでは不定期にデータが蓄積されていく**。

-   サービスの提供者は API 制限を気にすることなくツイートを集めることができる
-   サービスの受益者は手元にあるツイートを手軽に分析して付加価値を得られる

両者 win-win であるといえよう。

問題があるとすれば、知らず知らずのうちにデータを取得されたターゲットだが、ここまで特段の権利は侵害していないはずだし、Twitter 社の規約にも従っているはずだ。
ソーシャルシェア機能をつけると問題になるかもしれないが、こちらにも抜け道がある気がしないでもない。

アイデアは形になってこそ価値があるので、誰かに真似される前に実行に移したいなぁ（夏終わるまでにやりたいね）
